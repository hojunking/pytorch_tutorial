{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e3c688",
   "metadata": {},
   "source": [
    "### pytorch_tutorial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90529b7a-041b-46e8-87a1-d9731bbf9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cea3f57-fcaa-4508-8ea5-4e1b06eba5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0.dev20220824\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([4, 3])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "t1 = torch.zeros(4,3)\n",
    "print(t1)\n",
    "print(t1.shape)\n",
    "print(t1.dtype)\n",
    "print(t1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dff1727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2: \n",
      "tensor([0.5857, 0.5779])\n",
      "torch.Size([2])\n",
      "\n",
      "---------after unsqueeze-------\n",
      "tensor([[0.5857, 0.5779]])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.rand(2)\n",
    "print(\"t2: \")\n",
    "print(t2)\n",
    "print(t2.shape)\n",
    "\n",
    "print(\"\\n---------after unsqueeze-------\")\n",
    "t2_add_rank = t2.unsqueeze(0)\n",
    "print(t2_add_rank)\n",
    "print(t2_add_rank.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f1d9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([192])\n",
      "\n",
      "---after reshape----\n",
      "torch.Size([3, 8, 8])\n",
      "\n",
      "---after permute----\n",
      "torch.Size([8, 8, 3])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.rand(192) # 3*8*8\n",
    "print(t4.shape)\n",
    "\n",
    "t4 = t4.reshape(3,8,8)\n",
    "print(\"\\n---after reshape----\")\n",
    "print(t4.shape)\n",
    "\n",
    "t4 = t4.permute(1,2,0)\n",
    "print(\"\\n---after permute----\")\n",
    "print(t4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torch/cuda/__init__.py:150: UserWarning: \n",
      "NVIDIA GeForce RTX 3070 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 3070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "t1_gpu = t1.cuda(device)\n",
    "print(t1_gpu.device)\n",
    "print(t1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3d3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch(p.10)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
