{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.distributed as dist\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = dist.get_rank()\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1' #본인이 사용하고 싶은 GPU 넘버를 써주면 됨\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '23097'         # 좀 큰 숫자로 맞추면 됨 작은 숫자는 에러발생!\n",
    "\n",
    "\n",
    "torch.distributed.init_process_group(backend='nccl', init_method=\"env://\", rank =0, world_size=1)  # rank should be 0 ~ world_size-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev1:cuda:0 dev2:cuda:1\n"
     ]
    }
   ],
   "source": [
    "dev0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dev1 = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'dev1:{dev0} dev2:{dev1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../PYTORCH_NOTEBOOKS/Data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root='../PYTORCH_NOTEBOOKS/Data',train=True, download=True,transform = transform)\n",
    "test_data = datasets.MNIST(root='../PYTORCH_NOTEBOOKS/Data',train=False, download=True,transform = transform)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = DistributedSampler(train_data)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    "    #,sampler=train_sampler\n",
    "    )\n",
    "test_sampler = DistributedSampler(test_data)\n",
    "test_loader = DataLoader(\n",
    "train_data,\n",
    "batch_size=500,\n",
    "shuffle=False,\n",
    "num_workers=8,\n",
    "pin_memory=True\n",
    "#,sampler=test_sampler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}')) # FORMATTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST BATCH\n",
    "for images, labels in train_loader:\n",
    "    # 60,000 / 100 -> 60 times\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, dev0,dev1,in_sz=784, out_sz=10, layers=[120,84]):\n",
    "        super().__init__()\n",
    "        self.dev0 = dev0\n",
    "        self.dev1 = dev1\n",
    "        self.fc1= nn.Linear(in_sz, layers[0]).to(dev0)\n",
    "        self.fc2= nn.Linear(layers[0],layers[1]).to(dev0)\n",
    "        self.fc3= nn.Linear(layers[1],out_sz).to(dev1)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = X.to(self.dev0)\n",
    "        X = self.fc2(self.fc1(X))\n",
    "        X = X.to(self.dev1)\n",
    "        X = self.fc3(X).to(self.dev1)\n",
    "\n",
    "        return F.log_softmax(X,dim=1) # MULTI CLASS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MultilayerPerceptron(dev0,dev1)\n",
    "ddp_model = DDP(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94080\n",
      "120\n",
      "10080\n",
      "84\n",
      "840\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# ANN --> CNN\n",
    "for param in model.parameters():\n",
    "    print(param.numel()) ## number of elements\n",
    "# 105000, 214 parameters -> use more efficient CNN\n",
    "criterion = nn.CrossEntropyLoss().to(dev0)\n",
    "optimizer = torch.optim.Adam(ddp_model.parameters(), lr =0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 784])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten the datas\n",
    "images.shape # --> [100,784] 100 images (28*28) make to 1 dimension (784)\n",
    "images.view(100,-1).shape # combine the single dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 batch 400 loss 0.30057597160339355 accuracy: 92.825\n",
      "Epoch 1 batch 400 loss 0.298120379447937 accuracy: 92.9075\n",
      "Epoch 2 batch 400 loss 0.2975993752479553 accuracy: 92.9175\n",
      "Epoch 3 batch 400 loss 0.2966439127922058 accuracy: 92.9625\n",
      "Epoch 4 batch 400 loss 0.29550302028656006 accuracy: 92.9975\n",
      "Epoch 5 batch 400 loss 0.29630303382873535 accuracy: 92.995\n",
      "Epoch 6 batch 400 loss 0.29794514179229736 accuracy: 93.0325\n",
      "Epoch 7 batch 400 loss 0.30068671703338623 accuracy: 93.0575\n",
      "Epoch 8 batch 400 loss 0.3027072250843048 accuracy: 93.06\n",
      "Epoch 9 batch 400 loss 0.30403760075569153 accuracy: 93.0525\n",
      "Epoch 10 batch 400 loss 0.3051220178604126 accuracy: 93.055\n",
      "Epoch 11 batch 400 loss 0.30522048473358154 accuracy: 93.0525\n",
      "Epoch 12 batch 400 loss 0.305276095867157 accuracy: 93.0525\n",
      "Epoch 13 batch 400 loss 0.30426540970802307 accuracy: 93.0825\n",
      "Epoch 14 batch 400 loss 0.30487677454948425 accuracy: 93.105\n",
      "Epoch 15 batch 400 loss 0.3054546117782593 accuracy: 93.1325\n",
      "Epoch 16 batch 400 loss 0.3050174415111542 accuracy: 93.145\n",
      "Epoch 17 batch 400 loss 0.3042440414428711 accuracy: 93.165\n",
      "Epoch 18 batch 400 loss 0.30337613821029663 accuracy: 93.1725\n",
      "Epoch 19 batch 400 loss 0.30271828174591064 accuracy: 93.1625\n",
      "Duration :1.624817713101705 mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "## Training\n",
    "\n",
    "epochs =20\n",
    "\n",
    "# Trackers\n",
    "train_losses = []\n",
    "test_losses =[]\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        \n",
    "        # 10 Neurons\n",
    "        X_train = X_train.to(dev0)\n",
    "        y_train = y_train.to(dev0)\n",
    "        b +=1\n",
    "        y_pred = ddp_model(X_train.view(100,-1)) ## flatten\n",
    "        y_pred = y_pred.to(dev0)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "\n",
    "        predicted = torch.max(y_pred.data,1)[1] # [0.1,0.0,...0.8] get the best probability\n",
    "        # and get the real value in that index (flattened(1)) into predicted\n",
    "        batch_corr = (predicted == y_train).sum() # sum of how many correct count\n",
    "        trn_corr += batch_corr\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if b%400 == 0:\n",
    "            accuracy = 100* trn_corr.item() /(b*100)\n",
    "            print(f'Epoch {i} batch {b} loss {loss.item()} accuracy: {accuracy}')\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad(): ## no backprop & gradient\n",
    "\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            X_test = X_test.to(dev1)\n",
    "            y_test = y_test.to(dev1)\n",
    "            y_val = model(X_test.view(500,-1))\n",
    "            y_val = y_val.to(dev1)\n",
    "            predicted = torch.max(y_val,1)[1]\n",
    "            tst_corr += (predicted == y_test).sum() ##(batch_corr)\n",
    "\n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "\n",
    "\n",
    "total_time = time.time() -start_time\n",
    "print(f'Duration :{total_time/60} mins')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
